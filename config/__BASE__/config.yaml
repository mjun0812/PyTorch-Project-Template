# Training Params
BATCH: 16
CONTINUE_TRAIN: False
SEED: 42
SAVE_INTERVAL: 5

ITER_TRAIN: False
# Epoch Based
EPOCH: 200
VAL_INTERVAL: 5
# Iteration Based
MAX_ITER: 160000
STEP_ITER: 16000

# Device Params
GPU:
  USE: 0
  MULTI: False
CPU: False
# Dataloader worker
NUM_WORKER: 4
USE_RAM_CACHE: False

# Training Options
CUDNN: True
AMP: False
AMP_INIT_SCALE: null
AMP_DTYPE: "fp16"
MODEL_EMA: False
MODEL_EMA_DECAY: 0.99
USE_CLIP_GRAD: True
CLIP_GRAD_NORM: 10
COMPILE: False
COMPILE_BACKEND: "inductor"
ADJUST_LR: False

# Output
OUTPUT: ./result/
TAG: ""

# MLflow
USE_MLFLOW: True
MLFLOW_IGNORE_DIRS: ["models"]
MLFLOW_EXPERIMENT_NAME: "pytorch-project-template"
MLFLOW_LOG_CONGIG_PARAMS:
  - name: "Optimizer"
    value: "cfg.OPTIMIZER.NAME"
  - name: "LR scheduler"
    value: "cfg.LR_SCHEDULER.NAME"
  - name: "Learning Rate"
    value: "cfg.OPTIMIZER.LR"
  - name: "Epoch"
    value: "cfg.EPOCH"
  - name: "Model"
    value: "cfg.MODEL.NAME"
  - name: "Backbone"
    value: 'cfg.MODEL.get("BACKBONE", None)'
  - name: "Input size"
    value: 'cfg.MODEL.get("INPUT_SIZE")'
  - name: "Train_Dataset"
    value: "cfg.TRAIN_DATASET.NAME"
  - name: "Val_Dataset"
    value: "cfg.VAL_DATASET.NAME"
  - name: "Test_Dataset"
    value: "cfg.TEST_DATASET.NAME"
  - name: "Loss"
    value: "cfg.LOSS.NAME"
  - name: "Batch"
    value: "cfg.BATCH"
  - name: "GPU Ids"
    value: "cfg.GPU.USE"
